#!/usr/bin/env python3

import sys
import yaml

def config_logs(*flows, service):
	if not any(map(lambda flow: input_yaml[flow], flows)):
		service['logging'] = {'driver': 'none'}

input_yaml_file = open("./scripts/system-config.yaml")
input_yaml = yaml.load(input_yaml_file, Loader=yaml.FullLoader)

#### CONFIG VARIABLES
log_level = input_yaml['log_level']
log_bulk_rate = input_yaml['log_bulk_rate']
common_pool_size = input_yaml['common_pool_size']
reviews_streaming = input_yaml['reviews_streaming']

## BULKS
input1_bulk_size = input_yaml['input1_bulk_size']
joiner1_bulk_size = input_yaml['joiner1_bulk_size']
aggregator1_bulk_size = input_yaml['aggregator1_bulk_size']
aggregator7_bulk_size = input_yaml['aggregator7_bulk_size']
aggregator8_bulk_size = input_yaml['aggregator8_bulk_size']

## LOGGING
top_logging = input_yaml['top_logging']
bots_logging = input_yaml['bots_logging']
best_logging = input_yaml['best_logging']
funbiz_logging = input_yaml['funbiz_logging']
weekday_logging = input_yaml['weekday_logging']

## SYSTEM
users_reviews_threshold = input_yaml['users_reviews_threshold']
bots_reviews_threshold = input_yaml['bots_reviews_threshold']
funbiz_top_size = input_yaml['funbiz_top_size']

## NODES
joiner1_instances = 1
joiner3_instances = 1
aggregator1_instances = 1
aggregator2_instances = 1
aggregator4_instances = 1
aggregator5_instances = 1
aggregator7_instances = 1
aggregator8_instances = 1
mapper1_instances = input_yaml['mapper1_instances']
mapper2_instances = input_yaml['mapper2_instances']
mapper3_instances = input_yaml['mapper3_instances']
mapper4_instances = input_yaml['mapper4_instances']
mapper5_instances = input_yaml['mapper5_instances']
mapper6_instances = input_yaml['mapper6_instances']
filter1_instances = input_yaml['filter1_instances']
filter4_instances = input_yaml['filter4_instances']
filter5_instances = input_yaml['filter5_instances']
monitor_instances = input_yaml['monitor_instances']

business_data = '/data/business.json'	
reviews_inputs = 2 if reviews_streaming else 1

file = {}

#### VERSION
file['version'] = '3'

#### SERVICES
file['services'] = {}
containers = []

# Services dependencies
O1_DEPS = ['rabbitmq']
P1_DEPS = ['sink']
P2_DEPS = ['sink']
P3_DEPS = ['sink']
P4_DEPS = ['sink']
P5_DEPS = ['sink']
J1_DEPS = []
J3_DEPS = []
A1_DEPS = []
A2_DEPS = []
A4_DEPS = []
A5_DEPS = []
A7_DEPS = []
A8_DEPS = []
F1_DEPS = []
F4_DEPS = []
F5_DEPS = []
M1_DEPS = []
M2_DEPS = []
M3_DEPS = []
M4_DEPS = []
M5_DEPS = []
M6_DEPS = []
I1_DEPS = []
MON_DEPS = []

## RabbitMQ
file['services']['rabbitmq'] = {
	'container_name': f'rabbitmq',
	'image': 'rabbitmq:custom',
	'ports': ['15672:15672', '5672:5672'],
	'networks': ['testing_net'],
	'logging': {'driver': 'none'},
	'healthcheck': {
		'test': '''["CMD", "curl", "-f", "http://rabbitmq:156722]''',
		'interval': '10s',
		'timeout': '5s',
		'retries': '10'
	}
}

## Sink
service = 'sink'
containers += [service]
file['services'][service] = {
	'container_name': service,
	'image': f'{service}:latest',
	'entrypoint': '/sink',
	'restart': 'on-failure',
	'environment': ['O1_RABBITMQ_IP=rabbitmq', 'O1_RABBITMQ_PORT=5672', f'O1_LOG_LEVEL={log_level}'],
	'links': ['rabbitmq'],
	'depends_on': list(O1_DEPS),
	'networks': ['testing_net'],
}

## Funniest Cities flow
service = 'funcit_prettier'
containers += [service]
A2_DEPS += [service]
file['services'][service] = {
	'container_name': service,
	'image': f'{service}:latest',
	'entrypoint': '/prettier',
	'restart': 'on-failure',
	'environment': [f'P1_WORKERS_POOL={common_pool_size}', 'P1_RABBITMQ_IP=rabbitmq', 'P1_RABBITMQ_PORT=5672', f'P1_TOP_SIZE={funbiz_top_size}', f'P1_FUNCIT_TOPS={aggregator2_instances}', f'P1_LOG_LEVEL={log_level}'],
	'links': ['rabbitmq'],
	'depends_on': list(P1_DEPS),
	'networks': ['testing_net'],
}
config_logs('funbiz_logging', service=file['services'][service])

service = 'funcit_top'
for idx in range(0, aggregator2_instances):
	container = f'{service}{idx}'
	containers += [container]
	J1_DEPS += [container]
	file['services'][container] = {
		'container_name': container,
		'image': f'{service}:latest',
		'entrypoint': '/aggregator',
		'restart': 'on-failure',
		'environment': [f'A2_WORKERS_POOL={common_pool_size}', f'A2_LOG_BULK_RATE={log_bulk_rate}', f'A2_INSTANCE={idx}', 'A2_RABBITMQ_IP=rabbitmq', 'A2_RABBITMQ_PORT=5672', f'A2_TOP_SIZE={funbiz_top_size}', f'A2_FUNCIT_JOINERS={joiner1_instances}', f'A2_LOG_LEVEL={log_level}', f'A2_INPUT_TOPIC={idx}'],
		'links': ['rabbitmq'],
		'depends_on': list(A2_DEPS),
		'networks': ['testing_net'],
	}
	config_logs('funbiz_logging', service=file['services'][container])

service = 'funcit_joiner'
for idx in range(0, joiner1_instances):
	container = f'{service}{idx}'
	containers += [container]
	M1_DEPS += [container]
	A1_DEPS += [container]
	file['services'][container] = {
		'container_name': container,
		'image': f'{service}:latest',
		'entrypoint': '/joiner',
		'restart': 'on-failure',
		'environment': [f'J1_WORKERS_POOL={common_pool_size}', f'J1_LOG_BULK_RATE={log_bulk_rate}', f'J1_INSTANCE={idx}', 'J1_RABBITMQ_IP=rabbitmq', 'J1_RABBITMQ_PORT=5672', f'J1_FUNBIZ_AGGREGATORS={aggregator1_instances}', f'J1_CITBIZ_MAPPERS={mapper1_instances}', f'J1_FUNCIT_TOPS={aggregator2_instances}', f'J1_INPUT_TOPIC={idx}', f'J1_OUTPUT_BULK_SIZE={joiner1_bulk_size}', f'J1_LOG_LEVEL={log_level}'],
		'links': ['rabbitmq'],
		'depends_on': list(J1_DEPS),
		'networks': ['testing_net']
	}
	config_logs('funbiz_logging', service=file['services'][container])

service = 'citbiz_mapper'
for idx in range(0, mapper1_instances):
	container = f'{service}{idx}'
	containers += [container]
	I1_DEPS += [container]
	file['services'][container] = {
		'container_name': container,
		'image': f'{service}:latest',
		'entrypoint': '/mapper',
		'restart': 'on-failure',
		'environment': [f'M1_WORKERS_POOL={common_pool_size}', f'M1_LOG_BULK_RATE={log_bulk_rate}', f'M1_INSTANCE={idx}', 'M1_RABBITMQ_IP=rabbitmq', 'M1_RABBITMQ_PORT=5672', 'M1_BUSINESSES_INPUTS=1', f'M1_FUNCIT_JOINERS={joiner1_instances}', f'M1_LOG_LEVEL={log_level}'],
		'links': ['rabbitmq'],
		'depends_on': list(M1_DEPS),
		'networks': ['testing_net']
	}
	config_logs('funbiz_logging', service=file['services'][container])

service = 'biz_scatter'
containers += [service]
file['services'][service] = {
	'container_name': service,
	'image': f'{service}:latest',
	'entrypoint': '/scatter',
	'restart': 'on-failure',
	'environment': [f'I1_WORKERS_POOL={common_pool_size}', f'I1_LOG_BULK_RATE={log_bulk_rate}', 'I1_INSTANCE=0', f'I1_BUSINESS_DATA={business_data}', 'I1_RABBITMQ_IP=rabbitmq', 'I1_RABBITMQ_PORT=5672', f'I1_BULK_SIZE={input1_bulk_size}', f'I1_CITBIZ_MAPPERS={mapper1_instances}', f'I1_LOG_LEVEL={log_level}'],
	'links': ['rabbitmq'],
	'depends_on': list(I1_DEPS),
	'networks': ['testing_net'],
	'volumes': ['business_dataset:/data']
}
config_logs('funbiz_logging', service=file['services'][service])

service = 'funbiz_aggregator'
for idx in range(0, aggregator1_instances):
	container = f'{service}{idx}'
	containers += [container]
	F1_DEPS += [container]
	file['services'][container] = {
		'container_name': container,
		'image': f'{service}:latest',
		'entrypoint': '/aggregator',
		'restart': 'on-failure',
		'environment': [f'A1_WORKERS_POOL={common_pool_size}', f'A1_LOG_BULK_RATE={log_bulk_rate}', f'A1_INSTANCE={idx}', 'A1_RABBITMQ_IP=rabbitmq', 'A1_RABBITMQ_PORT=5672', f'A1_FUNBIZ_FILTERS={filter1_instances}', f'A1_FUNCIT_JOINERS={joiner1_instances}', f'A1_INPUT_TOPIC={idx}', f'A1_OUTPUT_BULK_SIZE={aggregator1_bulk_size}', f'A1_LOG_LEVEL={log_level}'],
		'links': ['rabbitmq'],
		'depends_on': list(A1_DEPS),
		'networks': ['testing_net']
	}
	config_logs('funbiz_logging', service=file['services'][container])

service = 'funbiz_filter'
for idx in range(0, filter1_instances):
	container = f'{service}{idx}'
	containers += [container]
	M2_DEPS += [container]
	file['services'][container] = {
		'container_name': container,
		'image': f'{service}:latest',
		'entrypoint': '/filter',
		'restart': 'on-failure',
		'environment': [f'F1_WORKERS_POOL={common_pool_size}', f'F1_LOG_BULK_RATE={log_bulk_rate}', f'F1_INSTANCE={idx}', 'F1_RABBITMQ_IP=rabbitmq', 'F1_RABBITMQ_PORT=5672', f'F1_FUNBIZ_MAPPERS={mapper2_instances}', f'F1_FUNBIZ_AGGREGATORS={aggregator1_instances}', f'F1_LOG_LEVEL={log_level}'],
		'links': ['rabbitmq'],
		'depends_on': list(F1_DEPS),
		'networks': ['testing_net']
	}
	config_logs('funbiz_logging', service=file['services'][container])

service = 'funbiz_mapper'
for idx in range(0, mapper2_instances):
	container = f'{service}{idx}'
	containers += [container]
	MON_DEPS += [container]
	file['services'][container] = {
		'container_name': container,
		'image': f'{service}:latest',
		'entrypoint': '/mapper',
		'restart': 'on-failure',
		'environment': [f'M2_WORKERS_POOL={common_pool_size}', f'M2_LOG_BULK_RATE={log_bulk_rate}', f'M2_INSTANCE={idx}', 'M2_RABBITMQ_IP=rabbitmq', 'M2_RABBITMQ_PORT=5672', f'M2_REVIEWS_INPUTS={reviews_inputs}', f'M2_FUNBIZ_FILTERS={filter1_instances}', f'M2_LOG_LEVEL={log_level}'],
		'links': ['rabbitmq'],
		'depends_on': list(M2_DEPS),
		'networks': ['testing_net']
	}
	config_logs('funbiz_logging', service=file['services'][container])

## Weekday Histogram flow.
service = 'weekday_prettier'
containers += [service]
A4_DEPS += [service]
file['services'][service] = {
	'container_name': service,
	'image': f'{service}:latest',
	'entrypoint': '/prettier',
	'restart': 'on-failure',
	'environment': [f'P2_WORKERS_POOL={common_pool_size}', 'P2_INSTANCE=0', 'P2_RABBITMQ_IP=rabbitmq', 'P2_RABBITMQ_PORT=5672', f'P2_WEEKDAY_AGGREGATORS={aggregator4_instances}', f'P2_LOG_LEVEL={log_level}'],
	'links': ['rabbitmq'],
	'depends_on': list(P2_DEPS),
	'networks': ['testing_net']
}
config_logs('weekday_logging', service=file['services'][service])

service = 'weekday_aggregator'
for idx in range(0, aggregator4_instances):
	container = f'{service}{idx}'
	containers += [container]
	M3_DEPS += [container]
	file['services'][container] = {
		'container_name': container,
		'image': f'{service}:latest',
		'entrypoint': '/aggregator',
		'restart': 'on-failure',
		'environment': [f'A4_WORKERS_POOL={common_pool_size}', f'A4_LOG_BULK_RATE={log_bulk_rate}', f'A4_INSTANCE={idx}', 'A4_RABBITMQ_IP=rabbitmq', 'A4_RABBITMQ_PORT=5672', f'A4_INPUT_TOPIC={idx}', f'A4_WEEKDAY_MAPPERS={mapper3_instances}', f'A4_LOG_LEVEL={log_level}'],
		'links': ['rabbitmq'],
		'depends_on': list(A4_DEPS),
		'networks': ['testing_net']
	}
	config_logs('weekday_logging', service=file['services'][container])

service = 'weekday_mapper'
for idx in range(0, mapper3_instances):
	container = f'{service}{idx}'
	containers += [container]
	MON_DEPS += [container]
	file['services'][container] = {
		'container_name': container,
		'image': f'{service}:latest',
		'entrypoint': '/mapper',
		'restart': 'on-failure',
		'environment': [f'M3_WORKERS_POOL={common_pool_size}', f'M3_LOG_BULK_RATE={log_bulk_rate}', f'M3_INSTANCE={idx}', 'M3_RABBITMQ_IP=rabbitmq', 'M3_RABBITMQ_PORT=5672', f'M3_REVIEWS_INPUTS={reviews_inputs}', f'M3_WEEKDAY_AGGREGATORS={aggregator4_instances}', f'M3_LOG_LEVEL={log_level}'],
		'links': ['rabbitmq'],
		'depends_on': list(M3_DEPS),
		'networks': ['testing_net']
	}
	config_logs('weekday_logging', service=file['services'][container])

## Best Users flow.
service = 'best_prettier'
containers += [service]
J3_DEPS += [service]
file['services'][service] = {
	'container_name': service,
	'image': f'{service}:latest',
	'entrypoint': '/prettier',
	'restart': 'on-failure',
	'environment': [f'P5_WORKERS_POOL={common_pool_size}', 'P5_RABBITMQ_IP=rabbitmq', 'P5_RABBITMQ_PORT=5672', f'P5_MIN_REVIEWS={users_reviews_threshold}', f'P5_BESTUSER_JOINERS={joiner3_instances}', f'P5_LOG_LEVEL={log_level}'],
	'links': ['rabbitmq'],
	'depends_on': list(P5_DEPS),
	'networks': ['testing_net']
}
config_logs('best_logging', service=file['services'][service])

service = 'best_joiner'
for idx in range(0, joiner3_instances):
	container = f'{service}{idx}'
	containers += [container]
	F4_DEPS += [container]
	A8_DEPS += [container]
	file['services'][container] = {
		'container_name': container,
		'image': f'{service}:latest',
		'entrypoint': '/joiner',
		'restart': 'on-failure',
		'environment': [f'J3_WORKERS_POOL={common_pool_size}', f'J3_LOG_BULK_RATE={log_bulk_rate}', f'J3_INSTANCE={idx}', 'J3_RABBITMQ_IP=rabbitmq', 'J3_RABBITMQ_PORT=5672', f'J3_INPUT_TOPIC={idx}', f'J3_STARS_AGGREGATORS={aggregator8_instances}', f'J3_USER_FILTERS={filter4_instances}', f'J3_LOG_LEVEL={log_level}'],
		'links': ['rabbitmq'],
		'depends_on': list(J3_DEPS),
		'networks': ['testing_net']
	}
	config_logs('best_logging', service=file['services'][container])

service = 'stars_aggregator'
for idx in range(0, aggregator8_instances):
	container = f'{service}{idx}'
	containers += [container]
	F5_DEPS += [container]
	file['services'][container] = {
		'container_name': container,
		'image': f'{service}:latest',
		'entrypoint': '/aggregator',
		'restart': 'on-failure',
		'environment': [f'A8_WORKERS_POOL={common_pool_size}', f'A8_LOG_BULK_RATE={log_bulk_rate}', f'A8_INSTANCE={idx}', 'A8_RABBITMQ_IP=rabbitmq', 'A8_RABBITMQ_PORT=5672', f'A8_INPUT_TOPIC={idx}', f'A8_STARS_FILTERS={filter5_instances}', f'A8_STARS_JOINERS={joiner3_instances}', f'A8_OUTPUT_BULK_SIZE={aggregator8_bulk_size}', f'A8_LOG_LEVEL={log_level}'],
		'links': ['rabbitmq'],
		'depends_on': list(A8_DEPS),
		'networks': ['testing_net']
	}
	config_logs('best_logging', service=file['services'][container])

service = 'stars_filter'
for idx in range(0, filter5_instances):
	container = f'{service}{idx}'
	containers += [container]
	M6_DEPS += [container]
	file['services'][container] = {
		'container_name': container,
		'image': f'{service}:latest',
		'entrypoint': '/filter',
		'restart': 'on-failure',
		'environment': [f'F5_WORKERS_POOL={common_pool_size}', f'F5_LOG_BULK_RATE={log_bulk_rate}', f'F5_INSTANCE={idx}', 'F5_RABBITMQ_IP=rabbitmq', 'F5_RABBITMQ_PORT=5672', f'F5_STARS_MAPPERS={mapper6_instances}', f'F5_STARS_AGGREGATORS={aggregator8_instances}', f'F5_LOG_LEVEL={log_level}'],
		'links': ['rabbitmq'],
		'depends_on': list(F5_DEPS),
		'networks': ['testing_net']
	}
	config_logs('best_logging', service=file['services'][container])

service = 'stars_mapper'
for idx in range(0, mapper6_instances):
	container = f'{service}{idx}'
	containers += [container]
	MON_DEPS += [container]
	file['services'][container] = {
		'container_name': container,
		'image': f'{service}:latest',
		'entrypoint': '/mapper',
		'restart': 'on-failure',
		'environment': [f'M6_WORKERS_POOL={common_pool_size}', f'M6_LOG_BULK_RATE={log_bulk_rate}', f'M6_INSTANCE={idx}', 'M6_RABBITMQ_IP=rabbitmq', 'M6_RABBITMQ_PORT=5672', f'M6_REVIEWS_INPUTS={reviews_inputs}', f'M6_STARS_FILTERS={filter5_instances}', f'M6_LOG_LEVEL={log_level}'],
		'links': ['rabbitmq'],
		'depends_on': list(M6_DEPS),
		'networks': ['testing_net']
	}
	config_logs('best_logging', service=file['services'][container])

# Bot Users flow.
service = 'bots_prettier'
containers += [service]
A5_DEPS += [service]
file['services'][service] = {
	'container_name': service,
	'image': f'{service}:latest',
	'entrypoint': '/prettier',
	'restart': 'on-failure',
	'environment': [f'P3_WORKERS_POOL={common_pool_size}', 'P3_RABBITMQ_IP=rabbitmq', 'P3_RABBITMQ_PORT=5672', f'P3_MIN_REVIEWS={bots_reviews_threshold}', f'P3_BOTS_AGGREGATORS={aggregator5_instances}', f'P3_LOG_LEVEL={log_level}'],
	'links': ['rabbitmq'],
	'depends_on': list(P3_DEPS),
	'networks': ['testing_net']
}
config_logs('bots_logging', service=file['services'][service])

service = 'bots_aggregator'
for idx in range(0, aggregator5_instances):
	container = f'{service}{idx}'
	containers += [container]
	M4_DEPS += [container]
	file['services'][container] = {
		'container_name': container,
		'image': f'{service}:latest',
		'entrypoint': '/aggregator',
		'restart': 'on-failure',
		'environment': [f'A5_WORKERS_POOL={common_pool_size}', f'A5_LOG_BULK_RATE={log_bulk_rate}', f'A5_INSTANCE={idx}', 'A5_RABBITMQ_IP=rabbitmq', 'A5_RABBITMQ_PORT=5672', f'A5_INPUT_TOPIC={idx}', f'A5_HASH_MAPPERS={mapper4_instances}', f'A5_MIN_REVIEWS={bots_reviews_threshold}', f'A5_LOG_LEVEL={log_level}'],
		'links': ['rabbitmq'],
		'depends_on': list(A5_DEPS),
		'networks': ['testing_net']
	}
	config_logs('bots_logging', service=file['services'][container])

service = 'hash_mapper'
for idx in range(0, mapper4_instances):
	container = f'{service}{idx}'
	containers += [container]
	MON_DEPS += [container]
	file['services'][container] = {
		'container_name': container,
		'image': f'{service}:latest',
		'entrypoint': '/mapper',
		'restart': 'on-failure',
		'environment': [f'M4_WORKERS_POOL={common_pool_size}', f'M4_LOG_BULK_RATE={log_bulk_rate}', f'M4_INSTANCE={idx}', 'M4_RABBITMQ_IP=rabbitmq', 'M4_RABBITMQ_PORT=5672', f'M4_REVIEWS_INPUTS={reviews_inputs}', f'M4_BOTS_AGGREGATORS={aggregator5_instances}', f'M4_LOG_LEVEL={log_level}'],
		'links': ['rabbitmq'],
		'depends_on': list(M4_DEPS),
		'networks': ['testing_net']
	}
	config_logs('bots_logging', service=file['services'][container])

## Top Users flow.
service = 'top_prettier'
containers += [service]
F4_DEPS += [service]
file['services'][service] = {
	'container_name': service,
	'image': f'{service}:latest',
	'entrypoint': '/prettier',
	'restart': 'on-failure',
	'environment': [f'P4_WORKERS_POOL={common_pool_size}', f'P4_LOG_BULK_RATE={log_bulk_rate}', 'P4_RABBITMQ_IP=rabbitmq', 'P4_RABBITMQ_PORT=5672', f'P4_MIN_REVIEWS={users_reviews_threshold}', f'P4_USER_FILTERS={filter4_instances}', f'P4_LOG_LEVEL={log_level}'],
	'links': ['rabbitmq'],
	'depends_on': list(P4_DEPS),
	'networks': ['testing_net']
}
config_logs('top_logging', service=file['services'][service])

service = 'user_filter'
for idx in range(0, filter4_instances):
	container = f'{service}{idx}'
	containers += [container]
	A7_DEPS += [container]
	file['services'][container] = {
		'container_name': container,
		'image': f'{service}:latest',
		'entrypoint': '/filter',
		'restart': 'on-failure',
		'environment': [f'F4_WORKERS_POOL={common_pool_size}', f'F4_LOG_BULK_RATE={log_bulk_rate}', f'F4_INSTANCE={idx}', 'F4_RABBITMQ_IP=rabbitmq', 'F4_RABBITMQ_PORT=5672', f'F4_MIN_REVIEWS={users_reviews_threshold}', f'F4_USER_AGGREGATORS={aggregator7_instances}', f'F4_STARS_JOINERS={joiner3_instances}', f'F4_LOG_LEVEL={log_level}'],
		'links': ['rabbitmq'],
		'depends_on': list(F4_DEPS),
		'networks': ['testing_net']
	}
	config_logs('top_logging', 'best_logging', service=file['services'][container])

service = 'user_aggregator'
for idx in range(0, aggregator7_instances):
	container = f'{service}{idx}'
	containers += [container]
	M5_DEPS += [container]
	file['services'][container] = {
		'container_name': container,
		'image': f'{service}:latest',
		'entrypoint': '/aggregator',
		'restart': 'on-failure',
		'environment': [f'A7_WORKERS_POOL={common_pool_size}', f'A7_LOG_BULK_RATE={log_bulk_rate}', f'A7_INSTANCE={idx}', 'A7_RABBITMQ_IP=rabbitmq', 'A7_RABBITMQ_PORT=5672', f'A7_INPUT_TOPIC={idx}', f'A7_USER_MAPPERS={mapper5_instances}', f'A7_USER_FILTERS={filter4_instances}', f'A7_OUTPUT_BULK_SIZE={aggregator7_bulk_size}', f'A7_LOG_LEVEL={log_level}'],
		'links': ['rabbitmq'],
		'depends_on': list(A7_DEPS),
		'networks': ['testing_net']
	}
	config_logs('top_logging', 'best_logging', 'bots_logging', service=file['services'][container])

service = 'user_mapper'
for idx in range(0, mapper5_instances):
	container = f'{service}{idx}'
	containers += [container]
	MON_DEPS += [container]
	file['services'][container] = {
		'container_name': container,
		'image': f'{service}:latest',
		'entrypoint': '/mapper',
		'restart': 'on-failure',
		'environment': [f'M5_WORKERS_POOL={common_pool_size}', f'M5_LOG_BULK_RATE={log_bulk_rate}', f'M5_INSTANCE={idx}', 'M5_RABBITMQ_IP=rabbitmq', 'M5_RABBITMQ_PORT=5672', f'M5_REVIEWS_INPUTS={reviews_inputs}', f'M5_USER_AGGREGATORS={aggregator7_instances}', f'M5_LOG_LEVEL={log_level}'],
		'links': ['rabbitmq'],
		'depends_on': list(M5_DEPS),
		'networks': ['testing_net']
	}
	config_logs('top_logging', 'best_logging', 'bots_logging', service=file['services'][container])

# service = 'monitor'
# monitors = list(map(lambda idx: f'{service}{idx}', list(range(0, monitor_instances))))
# for idx in range(0, monitor_instances):
# 	container = f'{service}{idx}'
# 	nodes = ','.join(containers)
# 	other_monitors = monitors
# 	other_monitors.remove(container)
# 	file['services'][container] = {
# 		'container_name': container,
# 		'image': f'{service}:latest',
# 		'entrypoint': '/monitor',
# 		'restart': 'on-failure',
# 		'environment': [f'MON_INSTANCE={idx}', f'MON_NODES={nodes}', f'MON_LOG_LEVEL={log_level}'],
# 		'links': ['rabbitmq'],
# 		'depends_on': list(MON_DEPS),
# 		'networks': ['testing_net']
# 	}

#### VOLUMES
file['volumes'] = {
	'business_dataset': {
		'driver': 'local',
		'driver_opts': {
			'type': 'none',
			'device': '$PWD/data/business',
			'o': 'bind'
		}
	}
}

#### NETWORK
file['networks'] = {
	'testing_net': {
		'ipam': {
			'driver': 'default', 
			'config': [
				{'subnet': '172.25.125.0/24'}
			]
		}
	}
}

with open('docker-compose-dev.yaml', 'w') as outfile:
    yaml.dump(file, outfile, default_flow_style=False)
